---
title: "BayesianCognitiveModeling"
output:
  rmdformats::downcute:
    highlight: kate
    css: mycss.css
    dev: "ragg_png"
date: "2024-04-30"
---

# 第一章　ベイズ分析の基礎
## 1.1 一般原則

* 能力$\theta$
  * ある問題へ正しく答える比率$\theta$と定義

* 事前分布
* 事後分布

* 数式
  * $p(\theta|D)=\frac{p(D|\theta)p(\theta)}{p(D)}$
  * $事後確率=\frac{尤度\times事前確立}{周辺尤度}$
  * $p(\theta|D)\propto p(D|\theta)p(\theta)$ : 事後確率は尤度と事前確立の積に比例する
  * 周辺尤度：データが得られる平均的確率(https://imaru.github.io/pubmemo/baba1.html#%E5%B0%A4%E5%BA%A6%E5%91%A8%E8%BE%BA%E5%B0%A4%E5%BA%A6)
  * 尤度：あるパラメータ条件で標本が得られる確率＝ある仮定のもとで、データが得られる確率

* 練習問題1.1.1
  * 公平なコイン投げ
    * 確率は0.5?
  * コインの位置と筋肉の緊張を正確に決められる場合は?
    * 0.5ではなくなる?
  * ぼんやりと未来が分かる場合は?
    * これも0.5ではなくなる?
  * 決まった確率はない、ということ?

* 練習問題1.1.2
  * " ある確率は他の確立より客観的"
  * "デ・フィネッティは間違っていて確率は明らかに決まっている"
  * デ・フィネッティは確率は決まっていないと言っている
  * でも、それはそういうもので、ある事象の確率はあるよね、と言っている?
  
* 練習問題1.1.3
  * 信用区間：95%の確信をもって$\theta$の真値はその区間の中にある。真値は確率分布。
  * 信頼区間：母平均は定数。信頼区間を求めたとき、それが真値を含まない区間であることが100回中5回ある。
  
* 練習問題1.1.4
  * 全問が正誤問題という情報は事前分布にどう影響する?
    * さっきは能力$\theta$は0から1で均等な値としていた
    * 能力だとしたら変わらない?
    * ある問いに正しく答える確率なら、能力がなくても0.5?
    
## 1.2 予測

* 事後分布$\theta$：すべての情報を含む
* この情報を使って予測する
* $\theta$が分かった状態で、新たな問題を5問
  * 結果を予測できるか
  * $\int p(k^{rep}|\theta,n^{rep}=5)p(\theta|n=10, k=9)d\theta$: ここで$p(k^{rep}|\theta,n^{rep}=5)$ は確率$\theta$という条件下で5回問題を解くとき、正解数が$k$である確率。$p(\theta|n=10, k=9)$はn回中kが9の確率（さっきの事後確率、今の事前確率）
  * で、これを$\theta$について積分するのが予測
  * コンピュータを使えば、ランダムな値$\theta_i$をサンプリング、それを使って$k^{rep}$を決めることで可能→分からん。なぜkが決まる? ある$\theta$が決まれば、正解回数が決まるからか。$\theta$の事前分布があるので、それに従って$\theta$を決めれば、kを出せる、それを繰り返すという理屈?
  
* 練習問題1.2.1
  * プラグイン原理とは[https://www.statlect.com/asymptotic-theory/plug-in-principle]: 所与の確率分布のある値（例えば期待値）は、その確率分布から抽出された観測地の経験的分布と同じ特徴を持つ
  * 最尤推定値に基づいて分布を考え、そこから値をサンプリングし、特徴量を求める。この方法の問題点とは。問題がない状況は？
    * 問題がない状況：事後分布を積分することでパラメータの不確実性を考慮できるのがいいって言ってるのだから、不確実性がないときにはプラグイン原理に基づく方法でいいということ？
    * 具体的には? パラメータが既知?ってことはない?
    
## 1.3 逐次的更新

* ベイズ：ソースの異なる情報の組み合わせに強い
  * 新しい情報による知識の更新
  * 情報が決まっていれば、更新のやり方は自由。最終的な事後分布は同じになる。
* 解析解を得られる場合と得られない場合
  * 事前分布がβ分布、尤度は二項分布? の組み合わせで事後分布はβ分布となる。この場合（共役）解析解が得られる。
  * そうじゃないときには解析解が得られない。どうするか。

## 1.4 マルコフ連鎖モンテカルロ(MCMC)

* ベイズ：事前分布と尤度から事後分布を得る（事後分布は予測にも使える）
  * ただし、これは限られた場合にしか解が得られなかった。モデルが複雑だと使えない。
* MCMC、コンピュータ主導のサンプリング*方法論*
  * 想像したモデルからサンプリング可能
  
```{r}
library(rstan)

rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())

dat1 <- read.csv('dat1.csv')

nsample<-nrow(dat1)
data_list<-list(k=dat1$cf, N=10, n=length(dat1))

mcmc_result<-stan(
  file='dat1.stan',
  data=data_list,
  seed=1,
  chains=3,
  iter=100,
  warmup=0,
  thin=1
)
print(mcmc_result, probs=c(0.025,0.5,0.975))
traceplot(mcmc_result)
stan_hist(mcmc_result)
stan_dens(mcmc_result)
```
## 過去の資料から

* MCMCとは何か（馬場本）：https://imaru.github.io/pubmemo/baba1.html#mcmc%E3%81%A8%E3%81%AF%E4%BD%95%E3%81%8B
* あるルールに従って更新すると、最終的にいいところに落ち着く話（馬場本：定常分布）：https://imaru.github.io/pubmemo/baba1.html#%E5%AE%9A%E5%B8%B8%E5%88%86%E5%B8%83
  * 携帯会社の初期比率が違う2つの地域があるときに、他社に移る確率が共通であれば、そのうち同じ比率に落ち着く
* MCMCアルゴリズムの一例（馬場本MH法）：https://imaru.github.io/pubmemo/baba1.html#%E3%83%A1%E3%83%88%E3%83%AD%E3%83%9D%E3%83%AA%E3%82%B9%E3%83%98%E3%82%A4%E3%82%B9%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E3%82%B9%E6%B3%95mh%E6%B3%95
  * ただ、これちょっと分かりにくい
* MCMCの前段階の例（緑本ふらふら試行錯誤による最尤推定）https://imaru.github.io/midori/midori8.html#%E4%BE%8B%E9%A1%8C-%E7%A8%AE%E5%AD%90%E3%81%AE%E7%94%9F%E5%AD%98%E7%A2%BA%E7%8E%87%E5%80%8B%E4%BD%93%E5%B7%AE%E3%81%AA%E3%81%97
  * 生存確率$q$の種子。1個体で8個観察。二項分布。20個体観察したデータが手元にあって、それを元に$q$を推測という話。これは解析的に解けるので、まずは解いた上で、サンプリング的に推定しようという話。
  * ふらふら推定は、適当な$q$から始めて、どんどん値を変えながらその値がデータと合うかどうかの計算するというやり方。